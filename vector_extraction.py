#!/usr/bin/env python3
"""
make_ft_vec.py
------------------------------------
â€¢ graphs é…ä¸‹ã®å„ case_* ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® third_joint_graph.json ã‚’ä¸€æ‹¬å‡¦ç†
  - ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ—ï¼‰ä½œæˆ
  - gensim.FastText å­¦ç¿’
  - ãƒãƒ¼ãƒ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’ .npy ã§ä¿å­˜ï¼ˆdataset/graphs/<graph_name>/vectors.npyï¼‰

ä½¿ã„æ–¹:
    python make_ft_vec.py \
        --graphdir ./graphs \
        --model fasttext_solana.bin \
        --dim 128 --epoch 20
"""
import argparse
import json
import os
import random
import glob

import numpy as np
from gensim.models import FastText
from tqdm import tqdm


def load_graph(path):
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)


def graph_to_sentences(g, n_walks=10, walk_len=6):
    id2node = {n['id']: n for n in g['nodes']}
    sents = [[n['label'], n.get('attributes', '')] for n in g['nodes']]
    adj = {}
    for e in g['edges']:
        adj.setdefault(e['source'], []).append(e['target'])
    for v in id2node:
        for _ in range(n_walks):
            cur, walk = v, []
            for _ in range(walk_len):
                walk.append(id2node[cur]['label'])
                if cur not in adj: break
                cur = random.choice(adj[cur])
            sents.append(walk)
    return sents


def train_fasttext(sentences, dim, epoch):
    return FastText(
        vector_size=dim,
        window=5,
        min_count=1,
        sg=1,
        epochs=epoch,
        sentences=sentences
    )


def save_node_vectors(g, model, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    vecs = []
    for n in g['nodes']:
        toks = [n['label'], n.get('attributes', '')]
        token_vecs = [model.wv[t] for t in toks if t in model.wv]
        if token_vecs:
            vec = np.mean(token_vecs, axis=0)
        else:
            # ãƒ¢ãƒ‡ãƒ«ã« 'unk' ãŒãªã„å ´åˆã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«
            vec = model.wv['unk'] if 'unk' in model.wv else np.zeros(model.vector_size)
        vecs.append(vec)
    out_path = os.path.join(output_dir, 'vectors.npy')
    np.save(out_path, np.vstack(vecs))
    print(f"Saved node vectors to {out_path}")


def save_labels(output_dir,label):
    os.makedirs(output_dir,exist_ok=True)
    out_path = os.path.join(output_dir, 'label.json')
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(label, f)
    print(f"Save graph label to {out_path}")


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--graphdir",
        default="./graphs",
        help="case_* ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å«ã‚€ graphs ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹"
    )
    ap.add_argument(
        "--model",
        default="fasttext_solana.bin",
        help="å­¦ç¿’æ¸ˆ FastText ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ‘ã‚¹"
    )
    ap.add_argument(
        "--vecdir",
        default="./dataset/graphs",
        help="å‡ºåŠ›ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
    )
    ap.add_argument("--dim",   type=int, default=64, help="FastText ã®æ¬¡å…ƒ")
    ap.add_argument("--epoch", type=int, default=20,  help="FastText ã® epoch")
    ap.add_argument("--label", type=list, default=[0,0,0,0,1,0,0,0,0,0],  help="sample data ã® ãƒ©ãƒ™ãƒ«")
    args = ap.parse_args()

    # 1) third_joint_graph.json ã‚’ã¾ã¨ã‚ã¦é›†ã‚ã‚‹
    pattern = os.path.join(args.graphdir, 'case_*', 'third_joint_graph.json')
    
    files = sorted(glob.glob(pattern))
    if not files:
        print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
        return

    # 2) ã‚³ãƒ¼ãƒ‘ã‚¹ç”Ÿæˆ
    print("ğŸ“š Generating corpus â€¦")
    sentences = []
    for p in tqdm(files):
        g = load_graph(p)
        sentences += graph_to_sentences(g)
    # unk ãƒˆãƒ¼ã‚¯ãƒ³
    sentences.append(["unk"])

    # 3) FastText å­¦ç¿’
    print("ğŸš€ Training FastText â€¦")
    ft = train_fasttext(sentences, args.dim, args.epoch)
    ft.save(args.model)
    print(f"âœ… model saved to {args.model}")

    # 4) å„ã‚°ãƒ©ãƒ•ã”ã¨ã«ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜
    print("ğŸ’¾ Saving node vectors â€¦")
    for p in tqdm(files):
        g      = load_graph(p)
        case_name = os.path.basename(os.path.dirname(p))
        outdir = os.path.join(args.vecdir, case_name)
        save_node_vectors(g, ft, outdir)
        save_labels(outdir,args.label)


    print("âœ… All done.")


if __name__ == "__main__":
    main()
